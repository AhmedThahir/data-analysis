# Homework Challenge (2 Extra Points)

Cross validation and the bootstrap are both **resampling methods**. A K-fold cross validation essentially generates K training sets and K validation sets at the same time, hence a K-fold CV is similar to a bootstrap that generates K samples. The key difference here (other than the two methods serving different purposes) is that the bootstrap samples *with replacement*. Each bootstrap sample can be as large or larger than the original data. On the other hand, each training/validation set generated by CV is a strict subset of the original data (indeed, each pair of them forms a partition of the original data). In this sense, CV is like a bootstrap that samples *without replacement*.

Questions:
1. Can we sample *with replacement* to estimate out-of-sample errors?
2. Can we sample *without replacement* to estimate coefficient standard errors and confidence intervals?

Challenge: design procedures to accomplish what these two questions ask for and compare the effectiveness of your procedures with CV and the bootstrap.
